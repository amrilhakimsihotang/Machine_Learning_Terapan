# -*- coding: utf-8 -*-
"""Project-Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14G-MxVlYc8-0FzfGv68x-JgB8O-e6jJI

Nama: Amril Hakim Sihotang<br>
Project : Prediksi Harga Emas untuk Pengambilan Keputusan Investasi

##Import library
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns


from google.colab import files
from google.colab import drive

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV

"""##Mengaitkan Google Drive dengan notebook Colab"""

drive.mount('/content/gdrive')

files.upload();

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets list

"""##Download dataset dari <br>
https://www.kaggle.com/datasets/ahmadkarrabi/gold-price-archive-2010-2023-dataset
"""

!kaggle datasets download -d ahmadkarrabi/gold-price-archive-2010-2023-dataset

"""##Ekstrak file yang sudah di download dan hasil ekstrak diletakkan di folder files"""

!unzip -q /content/gold-price-archive-2010-2023-dataset.zip -d /content/files

"""##Loading dataset gold price archive 2010-2023<br>"""

gold_resource='/content/files/XAUUSD_2010-2023.csv'
golds_data = pd.read_csv(gold_resource)
#untuk menghapus baris yang memiliki nilai yang hilang (NaN).
#Argumen inplace=True menyatakan bahwa perubahan akan diterapkan secara langsung pada DataFrame golds_data yang ada,
#tanpa perlu menetapkan hasilnya ke variabel baru.
golds_data.dropna(inplace=True)
golds_data

"""##Menampilkan jumlah nilai null dalam setiap kolom"""

print(golds_data.isnull().sum())

"""##Perintah untuk mendapatkan informasi tentang DataFrame golds_data"""

golds_data.info()

"""##Perintah yang digunakan untuk memberikan ringkasan <br>statistik deskriptif tentang DataFrame golds_data"""

golds_data.describe()

"""#Pengamatan terhadap outliers"""

sns.boxplot(data=golds_data[['open','high','low','close','rsi14','sma14']])
plt.xlabel('Features')
plt.show()

"""#Untuk memastikan kembali mengenai adanya outliers atau tidak<br> menggunakan metode Z-score"""

def calculate_z_score(df, columns):
    z_score_df = pd.DataFrame()

    for col in columns:
        col_zscore = col + '_zscore'
        z_score_df[col_zscore] = (df[col] - df[col].mean()) / df[col].std(ddof=0)

    return z_score_df

kolom = ['open', 'high', 'low', 'close', 'rsi14', 'sma14']

z_score_result = calculate_z_score(golds_data, kolom)

z_score_result.shape

"""#Menggunakan metode IQR untuk mengamati kembali adanya outliers"""

numeric_columns=['open','high','low','close','rsi14','sma14']
Q1 = golds_data[numeric_columns].quantile(0.25)
Q3 = golds_data[numeric_columns].quantile(0.75)
IQR = Q3-Q1
golds_data = golds_data[~((golds_data[numeric_columns] < (Q1 - 1.5 * IQR)) | (golds_data[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]

# Cek ukuran dataset setelah di drop outliers
golds_data.shape

"""#Univariate Analysis - price untuk Close"""

cols = 3
rows = 2
fig = plt.figure(figsize=(cols * 5, rows * 5))
numeric_columns=['open','high','low','close','rsi14','sma14']
for i, col in enumerate(numeric_columns):
  ax = fig.add_subplot(rows, cols, i + 1)
  sns.histplot(x=golds_data[col], bins=30, kde=True, ax=ax)
fig.tight_layout()
plt.show()

"""#Multivariate Analysis<br>
Melihat kolerasi fitur close terhadap fitur lain(open,high,low)<br>
dan terlihat, fitur close mempunyai dampak positif terhadap fitur lainnya
"""

sns.pairplot(golds_data[numeric_columns], diag_kind='kde')
plt.show()

"""Terlihat pada kolerasi matriks dibawah ini bahwa arah kolerasi bernilai positif."""

plt.figure(figsize=(15,8))
correlation_matrix = golds_data[numeric_columns].corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, vmin=-1, vmax=1, cmap='coolwarm', linewidth=0.5)
plt.title('Correlation Matrix untuk Fitur Numerik', size=20)
plt.show()

"""#Data Preparation<br>
Tahapan ini,akan dihapus beberapa kolom yang tidak diperlukan untuk membuat model untuk menghindari kegagalan dalam melakukan training. kolom yang tidak diperlukan adalah "time", "rsi14","sma14"<br>
kemudian menghapus nilai yang hilang dan menghapus duplikat data

"""

new_golds_data = golds_data.copy() # membuat salinan baru dari dataframe sebelumnya
new_golds_data.drop_duplicates(inplace=True) #Menghapus duplikat
new_golds_data.drop(['time','rsi14', 'sma14'], axis=1,inplace=True) #menghapus kolom yang tidak diperlukan
new_golds_data

"""#Tain-Test Split
Karena dataset ini cukup besar, maka pembagian dataset adalah 80:20
"""

# Acak urutan baris dalam DataFrame
new_golds_data = new_golds_data.sample(frac=1, random_state=42).reset_index(drop=True)
x = new_golds_data.drop(["close"],axis =1)
y = new_golds_data["close"]

# Bagi DataFrame menjadi data train dan data test menggunakan train_test_split
x_train_data, x_test_data,y_train_data,y_test_data = train_test_split(x,y, test_size=0.2, random_state=42)

print("Total sample data:", len(new_golds_data))
print("Jumlah baris data X train:", len(x_train_data))
print("Jumlah baris data y train:", len(y_train_data))
print("Jumlah baris data X test:", len(x_test_data))
print("Jumlah baris data y test:", len(y_test_data))

"""#Standarisasi <br>

"""

# Inisialisasi objek StandardScaler
scaler = StandardScaler()
# Implementasi fit_transform pada data train
train_data_scaled = scaler.fit_transform(x_train_data)
# Implementasi transform pada data test
test_data_scaled = scaler.transform(x_test_data)
#cetak
print("train data")
print(train_data_scaled[:5])
print("test data")
print(test_data_scaled[:5])

x_train_data.describe().round(4)

x_test_data.describe().round(4)

"""#Modeling<br>

"""

models = pd.DataFrame(index=['train_mse','test_mse'],columns=['KKN','RandomForest','Boosting','LR'])

# buat model prediksi
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(x_train_data, y_train_data)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(x_train_data), y_true=y_train_data)
# Prediksi menggunakan model KNN
y_pred_knn = knn.predict(x_test_data)
# Cetak hasil prediksi
print("Hasil prediksi menggunakan model KNN:")
print(y_pred_knn)
print(models.loc['train_mse','knn'] )

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(x_train_data, y_train_data)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(x_train_data), y_true=y_train_data)
# Prediksi menggunakan model RandomForest
y_pred_rf = RF.predict(x_test_data)
# Cetak hasil prediksi
print("Hasil prediksi menggunakan model RandomForest:")
print(y_pred_rf)
print(models.loc['train_mse', 'RandomForest'])

# buat model prediksi
boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(x_train_data, y_train_data)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(x_train_data), y_true=y_train_data)

# Prediksi menggunakan model Boosting
y_pred_boosting = boosting.predict(x_test_data)
# Cetak hasil prediksi
print("Hasil prediksi menggunakan model Bosting:")
print(y_pred_boosting)

print( models.loc['train_mse','Boosting'])

# buat model prediksi

linearregression = LinearRegression(n_jobs = -1)
linearregression.fit(x_train_data,y_train_data)
models.loc['train_mse','LR'] = mean_squared_error(y_pred=linearregression.predict(x_train_data), y_true=y_train_data)

# Prediksi menggunakan model LinearRegression
y_pred_lr = linearregression.predict(x_test_data)
# Cetak hasil prediksi
print("Hasil prediksi menggunakan model RandomForest:")
print(y_pred_lr)

print(models.loc['train_mse','LR'])

"""#Evaluation"""

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting','LR'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting,'LR':linearregression}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train_data, y_pred=model.predict(x_train_data))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test_data, y_pred=model.predict(x_test_data))/1e3
# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=True).plot(kind='barh', ax=ax, zorder=4)
ax.grid(zorder=0)

"""#Evaluasi<br>
Melakukan valuasi terhadap ke empat model yang ada untuk melihat hasil terbaik.
"""

prediksi = x_test_data.iloc[:1].copy()
pred_dict = {'y_true':y_test_data[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)